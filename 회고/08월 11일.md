# 6주 1일차 회고 (08.11)

- persist를 안 쓴다고 가정하고 각 3개의 메모리 사이즈를 넘어가면 어떻게 되는지에 대해 알려줘, Storage Memory, Execution Memory, User Memory

1. **Storage Memory**

- 역할: RDD/DataFrame 캐싱, broadcast 변수, shuffle 결과물 저장 등.
- persist/cache를 안 쓰면? → Storage 영역이 거의 사용되지 않음. 대신 shuffle, broadcast 같은 내부 연산에서만 일시적으로 사용.
- 사이즈를 넘어가면?
    1. persist 없음 → 필요 시 디스크에 spill(저장)하거나, 이미 저장된 블록을 제거(evict)하여 공간 확보.
    2. Execution Memory와 공유 → Unified Memory 환경에서는 Execution 메모리가 부족하지 않으면 Storage 영역이 Execution 메모리를 잠시 빌려 씀.
    3. 둘 다 꽉 찬 경우 → 더 이상 메모리에 블록을 유지할 수 없어 디스크 I/O 발생 → 성능 저하.

2. **Execution Memory**

- 역할: Shuffle, join, sort, aggregation 같은 실행 시 연산 버퍼.
- persist/cache를 안 쓰면? → 대부분의 메모리 사용은 Execution 영역에서 발생.
- 사이즈를 넘어가면?
    1. 연산 중간 결과를 디스크로 spill → Spark UI의 “Shuffle spill (memory)” 카운트 증가.
    2. Spill이 잦아지면 디스크 I/O 증가로 성능 저하.
    3. Execution Memory는 Storage Memory와 공유하므로, Storage가 남아있으면 빌려 쓸 수 있음.

3. **User Memory**

- 역할: Spark 내부가 아닌 사용자 코드(Python, Java, Scala 등)에서 할당한 객체 저장
- 사이즈를 넘어가면?
    1. Spark는 User Memory 영역을 자동 spill 하지 않음 → JVM GC(가비지 컬렉션) 발생.
    2. GC로도 메모리가 확보되지 않으면 → OutOfMemoryError 발생 → 작업 실패.
    3. User Memory는 Execution/Storage와 분리돼 있어, 부족하다고 해서 이쪽에서 빌려 쓸 수 없음.

---
### Review
- 피드백을 계속 받다보니 문제를 정의한다는 것을 어떤 식으로 해야하는지 얼추 잡혀가는 것 같다. 아직 디테일은 부족하지만 해야할 것이 무엇인지, 하지말아야할 것이 무엇인지 가닥이 잡혀가는 느낌이다

---
### Keep
- Spark를 최적화할 때 Application 단위가 아니라 Job 단위로 최적화해야한다는 개념을 배웠다.
- 아이디어의 pros/cons를 작성할 때 단순하게 본인이 처한 상황에서 적는 것이 아니라 고통을 받는 주체 입장에서 해당 고통을 겪었을 때를 고려해야한다는 것을 다시 한번 깨닫게 되었다.

---
### Problem

---
### Try
- 아이디어 구체화를 위해 고통의 상황을 가장 크게 겪는 사람이 누구인지, 극단적인 상황에 대해 재정의해보고, 그 사람이 가장 필요로 하는 것이 무엇일지를 생각해서 해결책을 작성해봐야겠다.
- aws 사용 전에 비용을 극단적으로 줄이면서, 사용자들의 요구 사항을 최대한 만족시킬 수 있는 기능과 프로세스가 무엇일지에 대해 설계해봐야겠다.
